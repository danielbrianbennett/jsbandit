source("~/Documents/Git/py-rl/reversal-learning/analysis/models/HMM.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/RW.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/WSLS.R")
system.time(
mle.fit <- mle(LL_RW,
start = start_WSLS,
fix = fix_WSLS,
method = "L-BFGS-B",
lower = lower_WSLS,
upper= upper_WSLS)
)
start_WSLS
?mle
# load packages
library(stats4)
# load data
load("~/Documents/Git/py-rl/reversal-learning/data/RLSummaryData_19-Oct-2016.RData")
# set participant ID
participantID <- "reversal_data_608"
# set input parameters for RW model
epsilon_start <- 0.5
rho_start <- 1
beta_start <- 0.1
# set input parameters for WSLS model
gamma_start <- 0.8
# Source models from separate files
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/ExtractParticipantData.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/HMM.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/RW.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/WSLS.R")
system.time(
mle.fit <- mle(minuslogl = LL_WSLS,
start = start_WSLS,
fix = fix_WSLS,
method = "L-BFGS-B",
lower = lower_WSLS,
upper= upper_WSLS)
)
mle.fit
# load packages
library(stats4)
# load data
load("~/Documents/Git/py-rl/reversal-learning/data/RLSummaryData_19-Oct-2016.RData")
# set participant ID
participantID <- "reversal_data_609"
# set input parameters for RW model
epsilon_start <- 0.5
rho_start <- 1
beta_start <- 0.1
# set input parameters for WSLS model
gamma_start <- 0.8
# Source models from separate files
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/ExtractParticipantData.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/HMM.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/RW.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/WSLS.R")
system.time(
mle.fit <- mle(minuslogl = LL_WSLS,
start = start_WSLS,
fix = fix_WSLS,
method = "L-BFGS-B",
lower = lower_WSLS,
upper= upper_WSLS)
)
mle.fit
print(mle.fit)
# load packages
library(stats4)
# load data
load("~/Documents/Git/py-rl/reversal-learning/data/RLSummaryData_19-Oct-2016.RData")
# set participant ID
participantID <- "reversal_data_609"
# set input parameters for RW model
epsilon_start <- 0.5
rho_start <- 1
beta_start <- 0.1
# set input parameters for WSLS model
gamma_start <- 0.8
# Source models from separate files
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/ExtractParticipantData.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/HMM.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/RW.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/WSLS.R")
system.time(
mle.fit <- mle(minuslogl = LL_WSLS,
start = start_WSLS,
fix = fix_WSLS,
method = "L-BFGS-B",
lower = lower_WSLS,
upper= upper_WSLS)
)
print(mle.fit)
mle.fit@coef
mle.fit@minuslogl()
mle.fit@minuslogl
mle.fit@min
# load packages
library(stats4)
# load data
load("~/Documents/Git/py-rl/reversal-learning/data/RLSummaryData_19-Oct-2016.RData")
# set participant ID
participantID <- "reversal_data_609"
# set input parameters for RW model
epsilon_start <- 0.5
rho_start <- 1
beta_start <- 0.1
# set input parameters for WSLS model
gamma_start <- 0.8
# Source models from separate files
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/ExtractParticipantData.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/HMM.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/RW.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/WSLS.R")
system.time(
mle.fit <- mle(minuslogl = LL_WSLS,
start = start_WSLS,
fix = fix_WSLS,
method = "L-BFGS-B",
lower = lower_WSLS,
upper= upper_WSLS)
)
print(mle.fit@coef)
print(mle.fit@min)
# load packages
library(stats4)
# load data
load("~/Documents/Git/py-rl/reversal-learning/data/RLSummaryData_19-Oct-2016.RData")
# set participant ID
participantID <- "reversal_data_609"
# set input parameters for RW model
epsilon_start <- 0.5
rho_start <- 1
beta_start <- 0.1
# set input parameters for WSLS model
gamma_start <- 0.8
# Source models from separate files
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/ExtractParticipantData.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/HMM.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/RW.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/WSLS.R")
system.time(
mle.fit <- mle(minuslogl = LL_RW,
start = start_RW,
fix = fix_RW,
method = "L-BFGS-B",
lower = lower_RW,
upper= upper_RW)
)
print(mle.fit@coef)
print(mle.fit@min)
# load packages
library(stats4)
# load data
load("~/Documents/Git/py-rl/reversal-learning/data/RLSummaryData_19-Oct-2016.RData")
# set participant ID
participantID <- "reversal_data_609"
# set input parameters for RW model
epsilon_start <- 0.5
rho_start <- 1
beta_start <- 0.1
# set input parameters for WSLS model
gamma_start <- 0.8
# Source models from separate files
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/ExtractParticipantData.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/HMM.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/RW.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/WSLS.R")
system.time(
mle.fit <- mle(minuslogl = LL_HMM,
start = start_HMM,
fix = fix_HMM,
method = "L-BFGS-B",
lower = lower_HMM,
upper= upper_HMM)
)
print(mle.fit@coef)
print(mle.fit@min)
# load packages
library(stats4)
# load data
load("~/Documents/Git/py-rl/reversal-learning/data/RLSummaryData_19-Oct-2016.RData")
# set participant ID
participantID <- "reversal_data_HC609"
# set input parameters for RW model
epsilon_start <- 0.5
rho_start <- 1
beta_start <- 0.1
# set input parameters for WSLS model
gamma_start <- 0.8
# Source models from separate files
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/ExtractParticipantData.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/HMM.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/RW.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/WSLS.R")
system.time(
mle.fit <- mle(minuslogl = LL_HMM,
start = start_HMM,
fix = fix_HMM,
method = "L-BFGS-B",
lower = lower_HMM,
upper= upper_HMM)
)
print(mle.fit@coef)
print(mle.fit@min)
# load packages
library(stats4)
# load data
load("~/Documents/Git/py-rl/reversal-learning/data/RLSummaryData_19-Oct-2016.RData")
# set participant ID
participantID <- "reversal_data_HC609"
# set input parameters for RW model
epsilon_start <- 0.5
rho_start <- 1
beta_start <- 0.1
# set input parameters for WSLS model
gamma_start <- 0.8
# Source models from separate files
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/ExtractParticipantData.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/HMM.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/RW.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/WSLS.R")
system.time(
mle.fit <- mle(minuslogl = LL_WSLS,
start = start_WSLS,
fix = fix_WSLS,
method = "L-BFGS-B",
lower = lower_WSLS,
upper= upper_WSLS)
)
print(mle.fit@coef)
print(mle.fit@min)
# load packages
library(stats4)
# load data
load("~/Documents/Git/py-rl/reversal-learning/data/RLSummaryData_19-Oct-2016.RData")
# set participant ID
participantID <- "reversal_data_HC609"
# set input parameters for RW model
epsilon_start <- 0.5
rho_start <- 1
beta_start <- 0.1
# set input parameters for WSLS model
gamma_start <- 0.8
# Source models from separate files
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/ExtractParticipantData.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/HMM.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/RW.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/WSLS.R")
system.time(
mle.fit <- mle(minuslogl = LL_RW,
start = start_RW,
fix = fix_RW,
method = "L-BFGS-B",
lower = lower_RW,
upper= upper_RW)
)
print(mle.fit@coef)
print(mle.fit@min)
load("~/Documents/Git/py-rl/reversal-learning/data/RLSummaryData_19-Oct-2016.RData")
length(unique(rlData$ID))
rlData
# load packages
library(stats4)
rm(mle.fit)
# load data
load("~/Documents/Git/py-rl/reversal-learning/data/RLSummaryData_19-Oct-2016.RData")
# set participant ID
participantID <- "reversal_data_616"
# Source models from separate files
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/ExtractParticipantData.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/HMM.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/RW.R")
source("~/Documents/Git/py-rl/reversal-learning/analysis/models/WSLS.R")
winAmount <- 100
lossAmount <- 0
# create containers
transitionProb <- vector(mode = "integer", length = nBandits)
likelihood <- vector(mode = "integer", length = nBandits)
tempProb <- vector(mode = "integer", length = nBandits)
beliefArray <- array(data = 0.5, dim = c(nBandits,nTrials+1,nBlocks))
allChoiceProb <- array(dim = c(nBandits,nTrials,nBlocks))
choiceProb <- matrix(0,nrow = nBlocks, ncol = nTrials)
for (iBlock in 1:nBlocks){
for (iTrial in 2:(nTrials+1)){
for (iState in 1:nBandits){ # loop through current states
# first loop to calculate main integral
for (iPrevState in 1:nBandits){
# calculate transition probability
if (iPrevState == iState){
transitionProb[iPrevState] <- gamma
} else if (iPrevState != iState){
transitionProb[iPrevState] <- 1 - gamma
}
# second loop to calculate integral in denominator
for (iiPrevState in 1:nBandits) {
if ( (points[iBlock,iTrial-1] == winAmount) & (iiPrevState == choices[iBlock,iTrial-1] + 1) ){
likelihood[iiPrevState] <- 0.5 + (0.5 * c)
} else if ( (points[iBlock,iTrial-1] == lossAmount) & (iiPrevState == choices[iBlock,iTrial-1] + 1) ){
likelihood[iiPrevState] <- 0.5 + (0.5 * -d)
} else if ( (points[iBlock,iTrial-1] == winAmount) & (iiPrevState != choices[iBlock,iTrial-1] + 1) ) {
likelihood[iiPrevState] <- 0.5 + (0.5 * -c)
} else if ( (points[iBlock,iTrial-1] == lossAmount) & (iiPrevState != choices[iBlock,iTrial-1] + 1) ) {
likelihood[iiPrevState] <- 0.5 + (0.5 * d)
}
}
tempProb[iPrevState] <- transitionProb[iPrevState] * ( (likelihood[iPrevState] * beliefArray[iPrevState,iTrial-1,iBlock]) / ((likelihood[1] * beliefArray[1,iTrial-1,iBlock]) + (likelihood[2] * beliefArray[2,iTrial-1,iBlock])) )
}
beliefArray[iState,iTrial,iBlock] <- sum(tempProb)
}
for (iState in 1:nBandits) {
allChoiceProb[iState,iTrial-1,iBlock] <- exp(beta * beliefArray[iState,iTrial-1,iBlock]) / sum(exp(beta * beliefArray[,iTrial-1,iBlock]))
}
choiceProb[iBlock,iTrial-1] <- allChoiceProb[choices[iBlock,iTrial-1] + 1,iTrial-1,iBlock]
}
}
gamma <- 0.8
c <- 0.3
d <- .3
# create containers
transitionProb <- vector(mode = "integer", length = nBandits)
likelihood <- vector(mode = "integer", length = nBandits)
tempProb <- vector(mode = "integer", length = nBandits)
beliefArray <- array(data = 0.5, dim = c(nBandits,nTrials+1,nBlocks))
allChoiceProb <- array(dim = c(nBandits,nTrials,nBlocks))
choiceProb <- matrix(0,nrow = nBlocks, ncol = nTrials)
for (iBlock in 1:nBlocks){
for (iTrial in 2:(nTrials+1)){
for (iState in 1:nBandits){ # loop through current states
# first loop to calculate main integral
for (iPrevState in 1:nBandits){
# calculate transition probability
if (iPrevState == iState){
transitionProb[iPrevState] <- gamma
} else if (iPrevState != iState){
transitionProb[iPrevState] <- 1 - gamma
}
# second loop to calculate integral in denominator
for (iiPrevState in 1:nBandits) {
if ( (points[iBlock,iTrial-1] == winAmount) & (iiPrevState == choices[iBlock,iTrial-1] + 1) ){
likelihood[iiPrevState] <- 0.5 + (0.5 * c)
} else if ( (points[iBlock,iTrial-1] == lossAmount) & (iiPrevState == choices[iBlock,iTrial-1] + 1) ){
likelihood[iiPrevState] <- 0.5 + (0.5 * -d)
} else if ( (points[iBlock,iTrial-1] == winAmount) & (iiPrevState != choices[iBlock,iTrial-1] + 1) ) {
likelihood[iiPrevState] <- 0.5 + (0.5 * -c)
} else if ( (points[iBlock,iTrial-1] == lossAmount) & (iiPrevState != choices[iBlock,iTrial-1] + 1) ) {
likelihood[iiPrevState] <- 0.5 + (0.5 * d)
}
}
tempProb[iPrevState] <- transitionProb[iPrevState] * ( (likelihood[iPrevState] * beliefArray[iPrevState,iTrial-1,iBlock]) / ((likelihood[1] * beliefArray[1,iTrial-1,iBlock]) + (likelihood[2] * beliefArray[2,iTrial-1,iBlock])) )
}
beliefArray[iState,iTrial,iBlock] <- sum(tempProb)
}
for (iState in 1:nBandits) {
allChoiceProb[iState,iTrial-1,iBlock] <- exp(beta * beliefArray[iState,iTrial-1,iBlock]) / sum(exp(beta * beliefArray[,iTrial-1,iBlock]))
}
choiceProb[iBlock,iTrial-1] <- allChoiceProb[choices[iBlock,iTrial-1] + 1,iTrial-1,iBlock]
}
}
beta <- 20\
beta <- 20
# create containers
transitionProb <- vector(mode = "integer", length = nBandits)
likelihood <- vector(mode = "integer", length = nBandits)
tempProb <- vector(mode = "integer", length = nBandits)
beliefArray <- array(data = 0.5, dim = c(nBandits,nTrials+1,nBlocks))
allChoiceProb <- array(dim = c(nBandits,nTrials,nBlocks))
choiceProb <- matrix(0,nrow = nBlocks, ncol = nTrials)
for (iBlock in 1:nBlocks){
for (iTrial in 2:(nTrials+1)){
for (iState in 1:nBandits){ # loop through current states
# first loop to calculate main integral
for (iPrevState in 1:nBandits){
# calculate transition probability
if (iPrevState == iState){
transitionProb[iPrevState] <- gamma
} else if (iPrevState != iState){
transitionProb[iPrevState] <- 1 - gamma
}
# second loop to calculate integral in denominator
for (iiPrevState in 1:nBandits) {
if ( (points[iBlock,iTrial-1] == winAmount) & (iiPrevState == choices[iBlock,iTrial-1] + 1) ){
likelihood[iiPrevState] <- 0.5 + (0.5 * c)
} else if ( (points[iBlock,iTrial-1] == lossAmount) & (iiPrevState == choices[iBlock,iTrial-1] + 1) ){
likelihood[iiPrevState] <- 0.5 + (0.5 * -d)
} else if ( (points[iBlock,iTrial-1] == winAmount) & (iiPrevState != choices[iBlock,iTrial-1] + 1) ) {
likelihood[iiPrevState] <- 0.5 + (0.5 * -c)
} else if ( (points[iBlock,iTrial-1] == lossAmount) & (iiPrevState != choices[iBlock,iTrial-1] + 1) ) {
likelihood[iiPrevState] <- 0.5 + (0.5 * d)
}
}
tempProb[iPrevState] <- transitionProb[iPrevState] * ( (likelihood[iPrevState] * beliefArray[iPrevState,iTrial-1,iBlock]) / ((likelihood[1] * beliefArray[1,iTrial-1,iBlock]) + (likelihood[2] * beliefArray[2,iTrial-1,iBlock])) )
}
beliefArray[iState,iTrial,iBlock] <- sum(tempProb)
}
for (iState in 1:nBandits) {
allChoiceProb[iState,iTrial-1,iBlock] <- exp(beta * beliefArray[iState,iTrial-1,iBlock]) / sum(exp(beta * beliefArray[,iTrial-1,iBlock]))
}
choiceProb[iBlock,iTrial-1] <- allChoiceProb[choices[iBlock,iTrial-1] + 1,iTrial-1,iBlock]
}
}
beliefArray
cbind(beliefArray[,,1])
cbind(beliefArray[1,,1])
cbind(beliefArray[1,,1], beliefArray[2,,1])
choices
choices[1,]
cbind(beliefArray[1,,1], beliefArray[2,,1],choices[1,])
cbind(beliefArray[1,2:41,1], beliefArray[2,2:41,1],choices[1,])
cbind(beliefArray[1,2:41,1], beliefArray[2,2:41,1],choices[1,],points[1,])
display <- cbind(beliefArray[1,2:41,1], beliefArray[2,2:41,1],choices[1,],points[1,])
View(display)
View(display)
## Set version number (make sure we only get the version of interest)
version.number <- 2.2
## Set directory parameters
base.directory <- "C:\\Users\\dbennett1\\Google Drive\\Works in Progress\\JSBANDIT\\Bandit\\analysis\\"
directory.separator <- "\\"
file.name <- "datadump_16Jan2016_1254PM.csv"
## Load datafile
input.file <- paste(base.directory, file.name, sep = directory.separator)
setwd(base.directory)
input.file <- "datadump_16Jan2016_1254PM.csv"
# this is the location you want the python parser to write the parsed CSV file
output.file <- "jsbandit.csv"
file.create(paste(base.directory,output.file, sep = directory.separator))
# run 'python parser.py input_file output_file'
system(paste('python parser.py', input.file, output.file))
# should print: Done parsing!
# read the results of parsing into R
parsed.data <- read.csv(file=output.file, header=T, stringsAsFactors=F)
# separate choice data from demographic data
unsorted.data <- parsed.data[which(!is.na(parsed.data$pointsWon)),]
unsorted.data <- unsorted.data[unsorted.data$language != "fakeparticipant",]
unsorted.data <- unsorted.data[unsorted.data$version == version.number,]
# resort data frame into a more legible format
sorted.data <- unsorted.data[order(unsorted.data$ID, unsorted.data$block, unsorted.data$trial),c(10,20,12,3,14,1,2,6)]
getwd()
setwd("~/Documents/Git/jsbandit/analysis")
## Set version number (make sure we only get the version of interest)
version.number <- 2.2
## Set directory parameters
base.directory <- "~/Documents/Git/jsbandit/analysis"
directory.separator <- "/"
file.name <- "datadump_16Jan2016_1254PM.csv"
## Load datafile
input.file <- paste(base.directory, file.name, sep = directory.separator)
setwd(base.directory)
input.file <- "datadump_16Jan2016_1254PM.csv"
# this is the location you want the python parser to write the parsed CSV file
output.file <- "jsbandit.csv"
file.create(paste(base.directory,output.file, sep = directory.separator))
# run 'python parser.py input_file output_file'
system(paste('python parser.py', input.file, output.file))
# should print: Done parsing!
# read the results of parsing into R
parsed.data <- read.csv(file=output.file, header=T, stringsAsFactors=F)
# separate choice data from demographic data
unsorted.data <- parsed.data[which(!is.na(parsed.data$pointsWon)),]
unsorted.data <- unsorted.data[unsorted.data$language != "fakeparticipant",]
unsorted.data <- unsorted.data[unsorted.data$version == version.number,]
# resort data frame into a more legible format
sorted.data <- unsorted.data[order(unsorted.data$ID, unsorted.data$block, unsorted.data$trial),c(10,20,12,3,14,1,2,6)]
## Set version number (make sure we only get the version of interest)
version.number <- 2.2
## Set directory parameters
base.directory <- "~/Google Drive/Works in Progress/JSBANDIT/Bandit/data"
directory.separator <- "/"
file.name <- "datadump_16Jan2016_1254PM.csv"
## Load datafile
input.file <- paste(base.directory, file.name, sep = directory.separator)
setwd(base.directory)
input.file <- "datadump_16Jan2016_1254PM.csv"
# this is the location you want the python parser to write the parsed CSV file
output.file <- "jsbandit.csv"
file.create(paste(base.directory,output.file, sep = directory.separator))
# run 'python parser.py input_file output_file'
system(paste('python parser.py', input.file, output.file))
# should print: Done parsing!
# read the results of parsing into R
parsed.data <- read.csv(file=output.file, header=T, stringsAsFactors=F)
# separate choice data from demographic data
unsorted.data <- parsed.data[which(!is.na(parsed.data$pointsWon)),]
unsorted.data <- unsorted.data[unsorted.data$language != "fakeparticipant",]
unsorted.data <- unsorted.data[unsorted.data$version == version.number,]
# resort data frame into a more legible format
sorted.data <- unsorted.data[order(unsorted.data$ID, unsorted.data$block, unsorted.data$trial),c(10,20,12,3,14,1,2,6)]
## Set version number (make sure we only get the version of interest)
version.number <- 2.2
## Set directory parameters
base.directory <- "~/Google Drive/Works in Progress/JSBANDIT/Bandit/analysis"
directory.separator <- "/"
file.name <- "datadump_16Jan2016_1254PM.csv"
## Load datafile
input.file <- paste(base.directory, file.name, sep = directory.separator)
setwd(base.directory)
input.file <- "datadump_16Jan2016_1254PM.csv"
# this is the location you want the python parser to write the parsed CSV file
output.file <- "jsbandit.csv"
file.create(paste(base.directory,output.file, sep = directory.separator))
# run 'python parser.py input_file output_file'
system(paste('python parser.py', input.file, output.file))
# should print: Done parsing!
# read the results of parsing into R
parsed.data <- read.csv(file=output.file, header=T, stringsAsFactors=F)
# separate choice data from demographic data
unsorted.data <- parsed.data[which(!is.na(parsed.data$pointsWon)),]
unsorted.data <- unsorted.data[unsorted.data$language != "fakeparticipant",]
unsorted.data <- unsorted.data[unsorted.data$version == version.number,]
# resort data frame into a more legible format
sorted.data <- unsorted.data[order(unsorted.data$ID, unsorted.data$block, unsorted.data$trial),c(10,20,12,3,14,1,2,6)]
sorted.data
head(sorted.data)
